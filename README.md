<div align="center">

# ğŸ”ª LLM Chunker

**LLM ê¸°ë°˜ ì˜ë¯¸ë¡ ì  í…ìŠ¤íŠ¸ ë¶„í•  ë¼ì´ë¸ŒëŸ¬ë¦¬**

[![PyPI version](https://badge.fury.io/py/llm-chunker.svg)](https://badge.fury.io/py/llm-chunker)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

_ê¸€ì ìˆ˜ê°€ ì•„ë‹Œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤._

[ì„¤ì¹˜](#-ì„¤ì¹˜) â€¢
[ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘) â€¢
[ì˜ˆì œ](#-ì˜ˆì œ) â€¢
[API ë ˆí¼ëŸ°ìŠ¤](#-api-ë ˆí¼ëŸ°ìŠ¤) â€¢
[English](README.en.md)

</div>

---

## âœ¨ ì™œ llm-chunkerì¸ê°€ìš”?

ê¸°ì¡´ ì²­ì»¤ëŠ” ê¸€ì ìˆ˜ë‚˜ ì •ê·œì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•´ì„œ, ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ì˜ë¦¬ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. **llm-chunker**ëŠ” ë§¥ë½ì„ ì´í•´í•©ë‹ˆë‹¤â€”ë²•ë¥  ë¬¸ì„œì˜ ì¡°í•­ ê²½ê³„, ì†Œì„¤ì˜ ê°ì • ë³€í™”, ì£¼ì œ ì „í™˜ ë“±ì„ ê°ì§€í•©ë‹ˆë‹¤.

| ê¸°ì¡´ ì²­í‚¹          | LLM Chunker          |
| ------------------ | -------------------- |
| ê¸€ì ìˆ˜ë¡œ ë¶„í•      | ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í•      |
| ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ì˜ë¦¼ | ì™„ì „í•œ ë¬¸ë§¥ ë³´ì¡´     |
| ì¼ë¥ ì ì¸ ë°©ì‹      | ë„ë©”ì¸ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ |

---

## ğŸ“¦ ì„¤ì¹˜

```bash
pip install llm-chunker
```

**ìš”êµ¬ì‚¬í•­:**

- Python 3.8+
- OpenAI API í‚¤

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

```python
import os
os.environ["OPENAI_API_KEY"] = "sk-..."

from llm_chunker import GenericChunker

chunker = GenericChunker()
chunks = chunker.split_text(your_text)  # list[str] ë°˜í™˜
```

---

## ğŸ“– ê¸°ë³¸ ì˜ˆì œ

```python
from llm_chunker import GenericChunker

chunker = GenericChunker(
    model="gpt-4o",
    significance_threshold=7,  # ì¤‘ìš”ë„ 7 ì´ìƒë§Œ ë¶„í• 
    min_chunk_gap=200,         # ë¶„í•  ì§€ì  ê°„ ìµœì†Œ ê±°ë¦¬
    verbose=True,              # ìƒì„¸ ë¡œê·¸ ì¶œë ¥
    show_progress=True,        # ì§„í–‰ë¥  + ê²°ê³¼ ì¶œë ¥
)

chunks = chunker.split_text(your_text)  # list[str]
```

---

## ğŸ“– ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì˜ˆì œ

### ë°©ë²• 1: PromptBuilder ì‚¬ìš©

```python
from llm_chunker import GenericChunker, TransitionAnalyzer, PromptBuilder

# ë„ë©”ì¸ê³¼ ì°¾ì„ ë‚´ìš©ë§Œ ì§€ì •í•˜ë©´ í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„±
prompt = PromptBuilder.create(
    domain="ì†Œì„¤",
    find="ê°ì • ë³€í™”ë‚˜ ì¥ë©´ ì „í™˜", # ì „í™˜ì  íŒì • ê¸°ì¤€ì„ ìƒì„¸íˆ ê¸°ìˆ 
)

analyzer = TransitionAnalyzer(
    prompt_generator=prompt,
    model="gpt-4o",
)

chunker = GenericChunker(analyzer=analyzer)
chunks = chunker.split_text(novel_text)
```

**PromptBuilder.create() íŒŒë¼ë¯¸í„°:**

| íŒŒë¼ë¯¸í„°             | íƒ€ì…  | ê¸°ë³¸ê°’               | ì„¤ëª…                 |
| -------------------- | ----- | -------------------- | -------------------- |
| `domain`             | `str` | `"text"`             | ë¶„ì„í•  í…ìŠ¤íŠ¸ ë„ë©”ì¸ |
| `find`               | `str` | `"semantic changes"` | ì°¾ì„ ì „í™˜ì  ìœ í˜•     |
| `custom_instruction` | `str` | `None`               | ì¶”ê°€ ì§€ì‹œì‚¬í•­        |

### ë°©ë²• 2: ë‚´ì¥ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ë²•ë¥  ë¬¸ì„œì— íŠ¹í™”) ì¶”ì²œ

```python
from llm_chunker import GenericChunker, TransitionAnalyzer
from llm_chunker.prompts import get_legal_prompt

analyzer = TransitionAnalyzer(
    prompt_generator=get_legal_prompt,
    model="gpt-4o",
)

chunker = GenericChunker(analyzer=analyzer)
chunks = chunker.split_text(legal_document)
```

ì¶”ê°€ ë‚´ì¥ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì˜ˆì •

### ë°©ë²• 3: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ ì§ì ‘ ì‘ì„±

ì˜ˆ)

```python
from llm_chunker import GenericChunker, TransitionAnalyzer

def my_custom_prompt(segment: str) -> str:
    return f"""
You are a 'Legal Document Structuring Expert' for RAG chunking.

PRIMARY OBJECTIVE:
Return chunk boundary points that maximize retrieval precision for legal QA.

TEXT SEGMENT:
{segment}

ABSOLUTE RULES (must follow):
A) STRUCTURAL HEADINGS MUST BE BOUNDARIES.
   If you see any of these, treat them as a new chunk start:
   - Korean law headings: "ì œNì¡°", "ì œNì¡°ì˜M", "ì œNì¥/ì ˆ/ê´€", "ë¶€ì¹™", "ë³„í‘œ"
   - English equivalents: "Article N", "Section N", "Chapter", "Part", "Schedule/Appendix"
   For EVERY detected new Article/Section heading (e.g., ì œ4ì¡° -> ì œ4ì¡°ì˜2),
   output a transition point with:
   - significance = 10
   - explanation mentions "STRUCTURAL HEADING"
   - start_text is the EXACT heading line as it appears in the text (do NOT paraphrase).

B) SIZE SAFETY (to avoid oversized chunks):
   Target chunk size: 900â€“1500 characters.
   Hard max (do not exceed): 2200 characters.
   If two consecutive structural headings would create an oversized chunk,
   you MUST add extra boundaries inside that range, using:
   - í•­/í˜¸/ëª© markers, â‘ â‘¡â‘¢â€¦, (1)(2)â€¦,
   - numbered lists "1. 2. 3.",
   - provisos/conditions like "ë‹¤ë§Œ", "ë‹¨ì„œ", "ì˜ˆì™¸", "íŠ¹ë¡€",
   - clause-type shifts (below).
   Any size-enforcement boundary should have significance 8â€“10.

C) CLAUSE-TYPE SHIFTS (often large even within same domain):
   Treat transitions between these legal functions as significant (usually 7â€“10):
   - Scope / What is taxed (ê³¼ì„¸ëŒ€ìƒ/ì •ì˜/ìš”ê±´/ë²”ìœ„)
   - Liability / Who pays (ë‚©ì„¸ì˜ë¬´ì/ì—°ëŒ€ë‚©ë¶€/ëŒ€ë¦¬ë‚©ë¶€)
   - Calculation mechanics (ê³¼ì„¸í‘œì¤€/ì„¸ìœ¨/ê°€ì‚°/ê³µì œ/í•œë„/ì‚°ì‹)
   - Procedure / Deadlines (ì‹ ê³ /ê¸°í•œ/ì ˆì°¨/ì„œë¥˜)
   - Jurisdiction / Authority (ê´€í• /ì„¸ë¬´ì„œ)
   - Exceptions (ë¹„ê³¼ì„¸/ë©´ì œ/íŠ¹ë¡€/ë‹¨ì„œ)

OUTPUT FORMAT:
Return ONE JSON object (no markdown):
{{
  "transition_points": [
    {{
      "start_text": "Exact quote where the NEW chunk begins (must match text exactly)",
      "topic_before": "Article/section + clause type BEFORE",
      "topic_after": "Article/section + clause type AFTER",
      "significance": <1-10 integer>,
      "explanation": "Reason: (1) structural heading OR (2) clause-type shift OR (3) size enforcement"
    }}
  ]
}}

CRITICAL VALIDATION (before final output):
- Every start_text MUST be an exact substring from the given segment.
- Prefer using heading lines as start_text because they match reliably.
- Do NOT invent text. If unsure, omit that point.
- Ensure all structural headings after the first are included as significance 10 boundaries.

If none, return {{ "transition_points": [] }}.
""".strip()

analyzer = TransitionAnalyzer(
    prompt_generator=my_custom_prompt,
    model="gpt-4o",
)

chunker = GenericChunker(analyzer=analyzer)
chunks = chunker.split_text(your_text)
```

---

## ğŸ“š API ë ˆí¼ëŸ°ìŠ¤

### `GenericChunker`

| íŒŒë¼ë¯¸í„°                 | íƒ€ì…                 | ê¸°ë³¸ê°’  | ì„¤ëª…                             |
| ------------------------ | -------------------- | ------- | -------------------------------- |
| `analyzer`               | `TransitionAnalyzer` | `None`  | ì»¤ìŠ¤í…€ ë¶„ì„ê¸° (í”„ë¡¬í”„íŠ¸/ëª¨ë¸)    |
| `model`                  | `str`                | `None`  | OpenAI ëª¨ë¸ëª… (analyzer ì—†ì„ ë•Œ) |
| `significance_threshold` | `int`                | `7`     | ìµœì†Œ ì¤‘ìš”ë„ ì ìˆ˜ (1-10)          |
| `min_chunk_gap`          | `int`                | `200`   | ë¶„í•  ì§€ì  ê°„ ìµœì†Œ ê±°ë¦¬ (ê¸€ì)    |
| `max_segment_size`       | `int`                | `5000`  | LLMì— ë³´ë‚¼ ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°         |
| `overlap_size`           | `int`                | `400`   | ì„¸ê·¸ë¨¼íŠ¸ ê°„ ì˜¤ë²„ë© í¬ê¸°          |
| `verbose`                | `bool`               | `False` | ìƒì„¸ ë¡œê·¸ ì¶œë ¥                   |
| `show_progress`          | `bool`               | `False` | ì§„í–‰ë¥  í‘œì‹œ + ì²­í¬ ê²°ê³¼ ì¶œë ¥     |

### `TransitionAnalyzer`

| íŒŒë¼ë¯¸í„°           | íƒ€ì…                   | ê¸°ë³¸ê°’               | ì„¤ëª…               |
| ------------------ | ---------------------- | -------------------- | ------------------ |
| `prompt_generator` | `Callable[[str], str]` | `get_default_prompt` | í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ |
| `model`            | `str`                  | `None`               | OpenAI ëª¨ë¸ëª…      |

---

## ğŸ—ï¸ ì‘ë™ ì›ë¦¬

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ê¸´ í…ìŠ¤íŠ¸ ì…ë ¥                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ë¶„í•       LLM ì»¨í…ìŠ¤íŠ¸ í¬ê¸°ì— ë§ê²Œ ìœˆë„ìš° ë¶„í•             â”‚
â”‚              (max_segment_size, overlap_size ì ìš©)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ë¶„ì„      LLM ê¸°ë°˜ ì „í™˜ì  íƒì§€                            â”‚
â”‚              (ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ ë„ë©”ì¸ ë§ì¶¤ ë¶„ì„)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. í•„í„°ë§    ë‚®ì€ ì¤‘ìš”ë„ & ì¤‘ë³µ í¬ì¸íŠ¸ ì œê±°                  â”‚
â”‚              (significance_threshold, min_chunk_gap ì ìš©)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ìŠ¬ë¼ì´ì‹±  ê²€ì¦ëœ ì „í™˜ì ì—ì„œ í…ìŠ¤íŠ¸ ë¶„í•                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
              [ì²­í¬ 1] [ì²­í¬ 2] [ì²­í¬ 3] ...
```

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License - [LICENSE](LICENSE) ì°¸ì¡°

---

## â­ Star History

<a href="https://star-history.com/#Theeojeong/llm-chunker&Date">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Theeojeong/llm-chunker&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Theeojeong/llm-chunker&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Theeojeong/llm-chunker&type=Date" />
 </picture>
</a>

---

<div align="center">

**ë” ë‚˜ì€ RAG íŒŒì´í”„ë¼ì¸ì„ ìœ„í•´ â¤ï¸**

ìœ ìš©í•˜ì…¨ë‹¤ë©´ [â­ ìŠ¤íƒ€](https://github.com/Theeojeong/llm-chunker)ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!

</div>
